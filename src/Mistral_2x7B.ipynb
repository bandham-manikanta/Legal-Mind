{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f7b3e7a-8f54-4849-96f7-0ee2947adef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "class LegalMixtralAPIAnswerer:\n",
    "    def __init__(self, hf_token: str, model_name: str = \"mistralai/Mixtral-8x7B-Instruct-v0.1\", max_new_tokens: int = 300):\n",
    "        self.api_url = f\"https://api-inference.huggingface.co/models/{model_name}\"\n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Bearer {hf_token}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        self.max_new_tokens = max_new_tokens\n",
    "\n",
    "    def build_prompt(self, query: str, context_docs: list) -> str:\n",
    "        context = \"\\n\\n\".join([f\"Context {i+1}:\\n{doc.strip()}\" for i, doc in enumerate(context_docs)])\n",
    "        prompt = (\n",
    "            f\"{context}\\n\\n\"\n",
    "            f\"Question: {query.strip()}\\n\\n\"\n",
    "            f\"Instructions: Based only on the above legal context, first provide a short answer to the question, \"\n",
    "            f\"then explain your reasoning in a separate paragraph.\\n\\n\"\n",
    "            f\"Answer:\"\n",
    "        )\n",
    "        return prompt\n",
    "\n",
    "    def generate(self, query: str, context_docs: list, debug: bool = False) -> dict:\n",
    "        prompt = self.build_prompt(query, context_docs)\n",
    "        payload = {\n",
    "            \"inputs\": prompt,\n",
    "            \"parameters\": {\n",
    "                \"max_new_tokens\": self.max_new_tokens,\n",
    "                \"do_sample\": False,\n",
    "                \"temperature\": 0.2,\n",
    "                \"return_full_text\": False\n",
    "            }\n",
    "        }\n",
    "\n",
    "        if debug:\n",
    "            print(\"🚀 Prompt sent to Hugging Face:\\n\", prompt)\n",
    "            print(\"-\" * 80)\n",
    "\n",
    "        response = requests.post(self.api_url, headers=self.headers, json=payload)\n",
    "\n",
    "        if response.status_code == 503:\n",
    "            estimated_time = response.json().get(\"estimated_time\", 10)\n",
    "            print(f\"⏳ Model loading... waiting {estimated_time} seconds\")\n",
    "            time.sleep(estimated_time)\n",
    "            return self.generate(query, context_docs, debug)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError(f\"❌ HF API Error {response.status_code}: {response.text}\")\n",
    "\n",
    "        full_output = response.json()[0][\"generated_text\"].strip()\n",
    "\n",
    "        # Try to split answer vs reasoning\n",
    "        if \"Reasoning:\" in full_output:\n",
    "            answer_part, reasoning_part = full_output.split(\"Reasoning:\", 1)\n",
    "        else:\n",
    "            lines = full_output.split(\"\\n\", 1)\n",
    "            answer_part = lines[0]\n",
    "            reasoning_part = lines[1] if len(lines) > 1 else \"\"\n",
    "\n",
    "        return {\n",
    "            \"answer\": answer_part.strip(),\n",
    "            \"reasoning\": reasoning_part.strip()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a019ebe-851f-4eeb-b44d-2c648a5268fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Prompt sent to Hugging Face:\n",
      " Context 1:\n",
      "The Fourth Amendment guarantees protection from unreasonable searches.\n",
      "\n",
      "Context 2:\n",
      "Evidence obtained without a warrant is usually inadmissible, but there are exceptions.\n",
      "\n",
      "Context 3:\n",
      "These include exigent circumstances, consent, and search incident to lawful arrest.\n",
      "\n",
      "Context 4:\n",
      "In Smith v. Ohio, the Court ruled that reasonable suspicion can sometimes justify limited searches.\n",
      "\n",
      "Question: Under what conditions can evidence from a warrantless search be admissible?\n",
      "\n",
      "Instructions: Based only on the above legal context, first provide a short answer to the question, then explain your reasoning in a separate paragraph.\n",
      "\n",
      "Answer:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "🧠 Answer: Evidence from a warrantless search can be admissible under the following conditions: exigent circumstances, consent, search incident to lawful arrest, and when there is reasonable suspicion.\n",
      "📚 Reasoning: Explanation: The Fourth Amendment guarantees protection from unreasonable searches, but the law recognizes certain exceptions where evidence obtained without a warrant can still be admitted. These exceptions include situations of exigent circumstances, such as when there is risk of harm or destruction of evidence. Consent also provides an exception, meaning if a person voluntarily agrees to a search, then any resulting evidence may be used. Additionally, if an arrest is lawful, a related search can occur without a warrant. Lastly, in the case of Smith v. Ohio, the court ruled that reasonable suspicion can sometimes justify limited searches. Therefore, these conditions allow for the admissibility of evidence from a warrantless search.\n"
     ]
    }
   ],
   "source": [
    "hf_token = \"use_hf_token_here\"\n",
    "query = \"Under what conditions can evidence from a warrantless search be admissible?\"\n",
    "context_docs = [\n",
    "    \"The Fourth Amendment guarantees protection from unreasonable searches.\",\n",
    "    \"Evidence obtained without a warrant is usually inadmissible, but there are exceptions.\",\n",
    "    \"These include exigent circumstances, consent, and search incident to lawful arrest.\",\n",
    "    \"In Smith v. Ohio, the Court ruled that reasonable suspicion can sometimes justify limited searches.\"\n",
    "]\n",
    "\n",
    "llm = LegalMixtralAPIAnswerer(hf_token)\n",
    "response = llm.generate(query, context_docs, debug=True)\n",
    "\n",
    "print(\"\\n🧠 Answer:\", response[\"answer\"])\n",
    "print(\"📚 Reasoning:\", response[\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f94d798-aaaa-4950-b986-0707328d46e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
