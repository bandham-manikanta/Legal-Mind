{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc671bcf-cc2e-4c93-9a60-0997e21a3fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "class LegalNVIDIAAnswerer:\n",
    "    def __init__(self, api_key, model=\"nvidia/llama-3.1-nemotron-70b-instruct\"):\n",
    "        self.client = OpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=\"https://integrate.api.nvidia.com/v1\"\n",
    "        )\n",
    "        self.model = model\n",
    "\n",
    "    def build_prompt(self, query, context_docs):\n",
    "        context = \"\\n\\n\".join([f\"Context {i+1}:\\n{doc.strip()}\" for i, doc in enumerate(context_docs)])\n",
    "        prompt = (\n",
    "            f\"{context}\\n\\n\"\n",
    "            f\"Question: {query.strip()}\\n\\n\"\n",
    "            f\"Answer with a complete response followed by a short reasoning.\\n\"\n",
    "            f\"Format:\\nAnswer: <your answer>\\nReasoning: <your reasoning>\"\n",
    "        )\n",
    "        return prompt\n",
    "\n",
    "    def generate(self, query, context_docs, debug=False, retries=3, wait_time=10):\n",
    "        prompt = self.build_prompt(query, context_docs)\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        \n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                completion = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=messages,\n",
    "                    temperature=0.3,\n",
    "                    top_p=1.0,\n",
    "                    max_tokens=1024,\n",
    "                    stream=False\n",
    "                )\n",
    "                response_text = completion.choices[0].message.content.strip()\n",
    "\n",
    "                if debug:\n",
    "                    print(\"üß† Raw Response:\\n\", response_text)\n",
    "\n",
    "                # Parse output\n",
    "                answer = \"\"\n",
    "                reasoning = \"\"\n",
    "                if \"Answer:\" in response_text:\n",
    "                    answer_part = response_text.split(\"Answer:\", 1)[-1]\n",
    "                    if \"Reasoning:\" in answer_part:\n",
    "                        answer, reasoning = answer_part.split(\"Reasoning:\", 1)\n",
    "                    else:\n",
    "                        answer = answer_part\n",
    "                else:\n",
    "                    answer = response_text\n",
    "\n",
    "                return {\n",
    "                    \"answer\": answer.strip(),\n",
    "                    \"reasoning\": reasoning.strip() if reasoning else \"(No explicit reasoning found)\"\n",
    "                }\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Attempt {attempt+1} failed: {e}\")\n",
    "                if attempt < retries - 1:\n",
    "                    print(f\"‚è≥ Retrying in {wait_time}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    raise RuntimeError(\"‚ùå All retries failed for NVIDIA LLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cadabd82-dd1b-4bd3-aed5-f3de366a152b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Raw Response:\n",
      " **Answer:** Yes, under certain conditions.\n",
      "**Reasoning:** This answer is based on the integration of information from Contexts 1, 2, and 4. Specifically, according to Carroll v. United States (Context 1), warrantless vehicle searches are allowed with probable cause, not mere suspicion (Context 4). The \"automobile exception\" (Context 2) provides the legal justification for this, highlighting the vehicle's mobility and the lower privacy expectation as key factors.\n",
      "\n",
      "‚úÖ Answer: ** Yes, under certain conditions.\n",
      "**\n",
      "üìö Reasoning: ** This answer is based on the integration of information from Contexts 1, 2, and 4. Specifically, according to Carroll v. United States (Context 1), warrantless vehicle searches are allowed with probable cause, not mere suspicion (Context 4). The \"automobile exception\" (Context 2) provides the legal justification for this, highlighting the vehicle's mobility and the lower privacy expectation as key factors.\n"
     ]
    }
   ],
   "source": [
    "query = \"Can police search a vehicle without a warrant under the Fourth Amendment?\"\n",
    "context_docs = [\n",
    "    \"In Carroll v. United States, the Court ruled that warrantless vehicle searches are permitted with probable cause.\",\n",
    "    \"The 'automobile exception' is justified by the inherent mobility of vehicles and lower expectation of privacy.\",\n",
    "    \"The scope of the search must be limited to areas where the evidence might reasonably be found.\",\n",
    "    \"Probable cause remains a prerequisite ‚Äî mere suspicion is not sufficient.\"\n",
    "]\n",
    "\n",
    "llm = LegalNVIDIAAnswerer(api_key=\"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\")\n",
    "response = llm.generate(query, context_docs, debug=True)\n",
    "\n",
    "print(\"\\n‚úÖ Answer:\", response[\"answer\"])\n",
    "print(\"üìö Reasoning:\", response[\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a988da3-9863-4852-9434-80529efcf722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
