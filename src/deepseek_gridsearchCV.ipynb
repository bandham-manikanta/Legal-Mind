{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "540da024-13fe-423d-963d-e96a20af0b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:   0%|                                       | 0/12 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Grid Search:   8%|â–ˆâ–ˆâ–Œ                            | 1/12 [01:21<14:53, 81.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config Tested: {'temperature': 0.1, 'top_p': 0.5, 'BLEU': 0.0042028326736153225, 'BERTScore': 0.8186533153057098}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 2/12 [02:43<13:38, 81.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config Tested: {'temperature': 0.1, 'top_p': 0.7, 'BLEU': 0.003888413256618598, 'BERTScore': 0.8186072409152985}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                       | 3/12 [03:56<11:39, 77.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config Tested: {'temperature': 0.1, 'top_p': 0.9, 'BLEU': 0.005975321676095607, 'BERTScore': 0.8230854868888855}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 4/12 [05:16<10:30, 78.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config Tested: {'temperature': 0.3, 'top_p': 0.5, 'BLEU': 0.00490566230729187, 'BERTScore': 0.8157976269721985}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                  | 5/12 [06:36<09:13, 79.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config Tested: {'temperature': 0.3, 'top_p': 0.7, 'BLEU': 0.004388964259907474, 'BERTScore': 0.8177266716957092}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ               | 6/12 [07:48<07:40, 76.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config Tested: {'temperature': 0.3, 'top_p': 0.9, 'BLEU': 0.005968258600816897, 'BERTScore': 0.8182619512081146}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 7/12 [08:59<06:13, 74.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config Tested: {'temperature': 0.5, 'top_p': 0.5, 'BLEU': 0.005578729351340995, 'BERTScore': 0.8187703490257263}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 8/12 [10:21<05:08, 77.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config Tested: {'temperature': 0.5, 'top_p': 0.7, 'BLEU': 0.005548084359336867, 'BERTScore': 0.8192568421363831}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž       | 9/12 [11:37<03:50, 76.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config Tested: {'temperature': 0.5, 'top_p': 0.9, 'BLEU': 0.0064409179070023664, 'BERTScore': 0.8205341100692749}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/12 [13:00<02:37, 78.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config Tested: {'temperature': 0.7, 'top_p': 0.5, 'BLEU': 0.004972050305451462, 'BERTScore': 0.8127470910549164}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 11/12 [14:22<01:19, 79.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config Tested: {'temperature': 0.7, 'top_p': 0.7, 'BLEU': 0.004939112373487706, 'BERTScore': 0.8198120594024658}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [15:43<00:00, 78.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config Tested: {'temperature': 0.7, 'top_p': 0.9, 'BLEU': 0.004144798123808805, 'BERTScore': 0.8208663463592529}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to deepseek_hyperparameter_tuning.csv and heatmap to deepseek_hyperparameter_heatmap.png\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from typing import List, Dict\n",
    "import itertools\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize BLEU and BERTScore metrics\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "bertscore_metric = evaluate.load(\"bertscore\")\n",
    "\n",
    "class LegalDeepseekAnswerer:\n",
    "    def __init__(self, api_key, model=\"deepseek-ai/deepseek-r1-distill-qwen-7b\"):\n",
    "        self.client = OpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=\"https://integrate.api.nvidia.com/v1\"\n",
    "        )\n",
    "        self.model = model\n",
    "\n",
    "    def generate(self, prompt, temperature=0.3, top_p=1.0, best_of_n=1, debug=False, retries=3, wait_time=10):\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        candidates = []\n",
    "\n",
    "        for _ in range(best_of_n):\n",
    "            for attempt in range(retries):\n",
    "                try:\n",
    "                    completion = self.client.chat.completions.create(\n",
    "                        model=self.model,\n",
    "                        messages=messages,\n",
    "                        temperature=temperature,\n",
    "                        top_p=top_p,\n",
    "                        max_tokens=1024,\n",
    "                        stream=False\n",
    "                    )\n",
    "                    response_text = completion.choices[0].message.content.strip()\n",
    "\n",
    "                    if debug:\n",
    "                        print(\"ðŸ§  Raw Response:\\n\", response_text)\n",
    "\n",
    "                    candidates.append(response_text)\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ Attempt {attempt+1} failed: {e}\")\n",
    "                    if attempt < retries - 1:\n",
    "                        print(f\"â³ Retrying in {wait_time}s...\")\n",
    "                        time.sleep(wait_time)\n",
    "                    else:\n",
    "                        raise RuntimeError(\"âŒ All retries failed for Deepseek\")\n",
    "\n",
    "        return candidates\n",
    "\n",
    "def simple_reranker(candidates: List[str]) -> str:\n",
    "    return max(candidates, key=lambda x: len(x))\n",
    "\n",
    "def evaluate_outputs(predictions: List[str], references: List[str]) -> Dict:\n",
    "    bleu = bleu_metric.compute(predictions=predictions,\n",
    "                               references=[[ref] for ref in references])['bleu']\n",
    "    bert = bertscore_metric.compute(predictions=predictions, references=references, lang='en')['f1']\n",
    "    bert_avg = sum(bert) / len(bert)\n",
    "    return {\"BLEU\": bleu, \"BERTScore\": bert_avg}\n",
    "\n",
    "def hyperparameter_grid_search(answerer: LegalDeepseekAnswerer,\n",
    "                                prompts: List[str],\n",
    "                                references: List[str],\n",
    "                                temperatures: List[float],\n",
    "                                top_ps: List[float],\n",
    "                                best_of_n: int = 3):\n",
    "    all_results = []\n",
    "    grid = list(itertools.product(temperatures, top_ps))\n",
    "\n",
    "    for temp, top_p in tqdm(grid, desc=\"Grid Search\"):\n",
    "        batch_predictions = []\n",
    "        for prompt in prompts:\n",
    "            candidates = answerer.generate(\n",
    "                prompt,\n",
    "                temperature=temp,\n",
    "                top_p=top_p,\n",
    "                best_of_n=best_of_n\n",
    "            )\n",
    "            best_answer = simple_reranker(candidates)\n",
    "            batch_predictions.append(best_answer)\n",
    "        scores = evaluate_outputs(batch_predictions, references)\n",
    "        result = {\n",
    "            \"temperature\": temp,\n",
    "            \"top_p\": top_p,\n",
    "            \"BLEU\": scores[\"BLEU\"],\n",
    "            \"BERTScore\": scores[\"BERTScore\"]\n",
    "        }\n",
    "        print(f\"Config Tested: {result}\")\n",
    "        all_results.append(result)\n",
    "\n",
    "    return all_results\n",
    "\n",
    "def log_results_and_plot(results: List[Dict], csv_path: str, heatmap_path: str):\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    pivot_bleu = df.pivot(index=\"temperature\", columns=\"top_p\", values=\"BLEU\")\n",
    "    sns.heatmap(pivot_bleu, annot=True, fmt=\".5f\", cmap=\"YlGnBu\")\n",
    "    plt.title(\"BLEU Score Heatmap\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    pivot_bert = df.pivot(index=\"temperature\", columns=\"top_p\", values=\"BERTScore\")\n",
    "    sns.heatmap(pivot_bert, annot=True, fmt=\".5f\", cmap=\"YlOrRd\")\n",
    "    plt.title(\"BERTScore Heatmap\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(heatmap_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"\\nResults saved to {csv_path} and heatmap to {heatmap_path}\")\n",
    "\n",
    "# =========================\n",
    "# Example Usage\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    API_KEY = \"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\"\n",
    "\n",
    "    answerer = LegalDeepseekAnswerer(api_key=API_KEY)\n",
    "\n",
    "    prompts = [\n",
    "        \"Question: What is the principle of stare decisis in US law? Answer and give reasoning.\",\n",
    "        \"Question: Can a minor legally enter into a binding contract? Explain with reasoning.\"\n",
    "    ]\n",
    "    references = [\n",
    "        \"Answer: The principle of stare decisis means that courts follow precedents established by higher courts. Reasoning: This ensures legal consistency and predictability.\",\n",
    "        \"Answer: Generally, a minor cannot enter into a binding contract, except for necessities. Reasoning: Contracts with minors are usually voidable to protect them from exploitation.\"\n",
    "    ]\n",
    "\n",
    "    temperatures = [0.1, 0.3, 0.5, 0.7]\n",
    "    top_ps = [0.5, 0.7, 0.9]\n",
    "\n",
    "    results = hyperparameter_grid_search(\n",
    "        answerer=answerer,\n",
    "        prompts=prompts,\n",
    "        references=references,\n",
    "        temperatures=temperatures,\n",
    "        top_ps=top_ps,\n",
    "        best_of_n=3\n",
    "    )\n",
    "\n",
    "    log_results_and_plot(\n",
    "        results,\n",
    "        csv_path=\"deepseek_hyperparameter_tuning.csv\",\n",
    "        heatmap_path=\"deepseek_hyperparameter_heatmap.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f16891-64bb-46ef-bc7a-d08374cb267d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
